{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKld6vfkOfvP",
        "outputId": "d21d0aa1-e1f2-441a-b9f4-5606d6649728"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "openjdk-8-jdk-headless is already the newest version (8u382-ga-1~22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 9 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "6LDx7ZfZTGWd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "metadata": {
        "id": "gIP3q1dRTI4f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "VStmMzPATMUn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ID of the files on Google Drive\n",
        "id = '1X0H850pVBBPctX4Z5otUn714_GLRWVtH'\n",
        "\n",
        "# Download 'graph-full.txt'\n",
        "graph_downloaded = drive.CreateFile({'id': id})\n",
        "graph_downloaded.GetContentFile('graph-full.txt')"
      ],
      "metadata": {
        "id": "EVZW5nKFTTn-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1a)"
      ],
      "metadata": {
        "id": "BB9ml95OUgy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "import re\n",
        "from itertools import combinations\n",
        "import numpy as np\n",
        "\n",
        "# Set up Spark configuration\n",
        "conf = SparkConf()\n",
        "# Initialize Spark context\n",
        "sc = SparkContext(conf=conf)\n",
        "\n",
        "\n",
        "BETA = 0.8 # Damping factor for PageRank\n",
        "MAX_ITER = 40 # Maximum number of iterations for PageRank\n",
        "N = 1000 # Number of nodes in the graph\n",
        "\n",
        "# Path to the input graph data file\n",
        "path = \"graph-full.txt\"\n",
        "# Read input data using Spark\n",
        "data = sc.textFile(path)"
      ],
      "metadata": {
        "id": "Z1iS1IMlVN5X"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx3tggjIOFXO",
        "outputId": "f884fa49-43a6-4525-80ca-af953c86c641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top:\n",
            "id: 263, score: 0.0020202911815182184\n",
            "id: 537, score: 0.00194334157145315\n",
            "id: 965, score: 0.001925447807166263\n",
            "id: 243, score: 0.001852634016241731\n",
            "id: 285, score: 0.0018273721700645144\n",
            "\n",
            "Bottom:\n",
            "id: 558, score: 0.0003286018525215297\n",
            "id: 93, score: 0.0003513568937516577\n",
            "id: 62, score: 0.00035314810510596274\n",
            "id: 424, score: 0.00035481538649301454\n",
            "id: 408, score: 0.00038779848719291705\n"
          ]
        }
      ],
      "source": [
        "# Load edges and combine the same edges\n",
        "edges = (data.map(lambda line: tuple(map(int, re.split(r'\\t+', line))))\n",
        "         .groupByKey()\n",
        "         .mapValues(lambda x: sorted(list(set(v for v in x))))\n",
        "         .sortByKey())\n",
        "\n",
        "# Obtain outgoing degrees\n",
        "inv_d = edges.map(lambda x: 1 / len(x[1])).collect()\n",
        "\n",
        "# Graph\n",
        "graph = (edges.flatMapValues(lambda x: x)\n",
        "         .map(lambda x: (x[1], x[0]))\n",
        "         .groupByKey()\n",
        "         .mapValues(lambda x: [(v, inv_d[v - 1]) for v in x])\n",
        "         .sortByKey())\n",
        "\n",
        "# Initialize r\n",
        "N = edges.count()\n",
        "r = [1 / N] * N\n",
        "\n",
        "# PageRank\n",
        "def pagerank(r, m):\n",
        "    return m.mapValues(lambda x: sum([r[v[0] - 1] * v[1] * BETA for v in x]))\\\n",
        "            .mapValues(lambda x: x + (1 - BETA)/N)\\\n",
        "            .map(lambda lines: lines[1]).collect()\n",
        "\n",
        "# Iterate\n",
        "def iterate(r, m):\n",
        "    for j in range(MAX_ITER):\n",
        "        r = pagerank(r, m)\n",
        "    return r\n",
        "\n",
        "# Print Results\n",
        "def find_and_print_top_bottom(r):\n",
        "    r_sorted = sorted(r)\n",
        "    r_array = np.array(r)\n",
        "\n",
        "    top = [(np.where(r_array == r_sorted[-j - 1])[0][0] + 1, r_sorted[-j - 1]) for j in range(5)]\n",
        "    bottom = [(np.where(r_array == r_sorted[j])[0][0] + 1, r_sorted[j]) for j in range(5)]\n",
        "\n",
        "    print('Top:')\n",
        "    for node_id, score in top:\n",
        "        print(f'id: {node_id}, score: {score}')\n",
        "\n",
        "    print('\\nBottom:')\n",
        "    for node_id, score in bottom:\n",
        "        print(f'id: {node_id}, score: {score}')\n",
        "\n",
        "r = iterate(r, graph)\n",
        "find_and_print_top_bottom(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1b)"
      ],
      "metadata": {
        "id": "c1xtZkamih3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load edges and combine the same edges\n",
        "l = (data.map(lambda line: tuple(map(int, re.split(r'\\t+', line))))\n",
        "         .groupByKey()\n",
        "         .mapValues(lambda x: sorted(list(set(v for v in x))))\n",
        "         .sortByKey())\n",
        "\n",
        "# Link matrix\n",
        "def LT(rdd):\n",
        "    return rdd.flatMapValues(lambda x: x)\\\n",
        "              .map(lambda x: (x[1], x[0]))\\\n",
        "              .groupByKey()\\\n",
        "              .mapValues(lambda x: [v for v in x])\\\n",
        "              .sortByKey()\n",
        "\n",
        "# Compute a\n",
        "def A(h, lt):\n",
        "    return lt.mapValues(lambda x: sum([h[v-1] for v in x]))\\\n",
        "             .map(lambda lines: lines[1]).collect()\n",
        "\n",
        "# Compute h\n",
        "def H(a, l):\n",
        "    return l.mapValues(lambda x: sum([a[v-1] for v in x]))\\\n",
        "            .map(lambda lines: lines[1]).collect()\n",
        "\n",
        "# Iterate\n",
        "def iterate_b(h, l, lt):\n",
        "    for _ in range(MAX_ITER):\n",
        "        a = A(h, lt)\n",
        "        a_max = max(a)\n",
        "        for i in range(len(a)):\n",
        "            a[i] /= a_max\n",
        "        h = H(a, l)\n",
        "        h_max = max(h)\n",
        "        for i in range(len(h)):\n",
        "            h[i] /= h_max\n",
        "    return a, h\n",
        "\n",
        "\n",
        "# Find the high and low nodes\n",
        "def high_and_low(r):\n",
        "    r_sorted = sorted(r)\n",
        "    r = np.array(r)\n",
        "    low = []\n",
        "    high = []\n",
        "    for j in range(5):\n",
        "        low.append((np.where(r == r_sorted[j])[0][0] + 1, r_sorted[j]))\n",
        "        high.append((np.where(r == r_sorted[-j - 1])[0][0] + 1, r_sorted[-j - 1]))\n",
        "    return high, low\n",
        "\n",
        "# Print results\n",
        "def print_results_b(high_a, low_a, high_h, low_h):\n",
        "    print('High Hubbiness:')\n",
        "    for i in range(5):\n",
        "        print('id: ' + str(high_h[i][0]) + ', score: ' + str(high_h[i][1]))\n",
        "    print('\\nLow Hubbiness:')\n",
        "    for i in range(5):\n",
        "        print('id: ' + str(low_h[i][0]) + ', score: ' + str(low_h[i][1]))\n",
        "    print('\\nHigh Authority:')\n",
        "    for i in range(5):\n",
        "        print('id: ' + str(high_a[i][0]) + ', score: ' + str(high_a[i][1]))\n",
        "    print('\\nLow Authority:')\n",
        "    for i in range(5):\n",
        "        print('id: ' + str(low_a[i][0]) + ', score: ' + str(low_a[i][1]))\n",
        "\n",
        "# Initialize h directly\n",
        "h = [1] * N\n",
        "# Compute Link Matrix (lt)\n",
        "lt = LT(l)\n",
        "# Iterate to compute 'a' and 'h'\n",
        "a, h = iterate_b(h, l, lt)\n",
        "# Find the high and low nodes for 'a' and 'h'\n",
        "high_a, low_a = high_and_low(a)\n",
        "high_h, low_h = high_and_low(h)\n",
        "# Print the results\n",
        "print_results_b(high_a, low_a, high_h, low_h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in1cZnkIUqGR",
        "outputId": "e5a5098d-d9af-4caa-f340-10b53569a424"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "High Hubbiness:\n",
            "id: 840, score: 1.0\n",
            "id: 155, score: 0.9499618624906543\n",
            "id: 234, score: 0.8986645288972263\n",
            "id: 389, score: 0.8634171101843789\n",
            "id: 472, score: 0.8632841092495218\n",
            "\n",
            "Low Hubbiness:\n",
            "id: 23, score: 0.04206685489093652\n",
            "id: 835, score: 0.057790593544330145\n",
            "id: 141, score: 0.06453117646225177\n",
            "id: 539, score: 0.0660265937341849\n",
            "id: 889, score: 0.07678413939216452\n",
            "\n",
            "High Authority:\n",
            "id: 893, score: 1.0\n",
            "id: 16, score: 0.9635572849634398\n",
            "id: 799, score: 0.9510158161074015\n",
            "id: 146, score: 0.9246703586198443\n",
            "id: 473, score: 0.899866197360405\n",
            "\n",
            "Low Authority:\n",
            "id: 19, score: 0.05608316377607618\n",
            "id: 135, score: 0.06653910487622794\n",
            "id: 462, score: 0.07544228624641901\n",
            "id: 24, score: 0.08171239406816942\n",
            "id: 910, score: 0.08571673456144875\n"
          ]
        }
      ]
    }
  ]
}