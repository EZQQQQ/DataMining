{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGIun_jD53vd"
      },
      "source": [
        "# Q2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqGXWK3q3Fl5",
        "outputId": "41d50744-258d-4354-f5c8-de3f71c504fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "openjdk-8-jdk-headless is already the newest version (8u382-ga-1~22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l5prbEif3YWn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u6XRQS0p3Y_O"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f_5Zc10i3avb"
      },
      "outputs": [],
      "source": [
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UmXMlJJO3ca8"
      },
      "outputs": [],
      "source": [
        "# ID of the file on Google Drive\n",
        "id = '18dmpXLkhaXA3o6eqckTeyp7exz_jsEFS'\n",
        "\n",
        "# Download 'sales-data-set.csv'\n",
        "facebook_downloaded = drive.CreateFile({'id': id})\n",
        "facebook_downloaded.GetContentFile('ego-facebook.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "u4XiDvcC4CD7"
      },
      "outputs": [],
      "source": [
        "# Initialize Spark\n",
        "conf = SparkConf().setAppName(\"PeopleYouMightKnow\")\n",
        "sc = SparkContext(conf=conf)\n",
        "\n",
        "# Load the friendship data from the input file\n",
        "data = sc.textFile(\"ego-facebook.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Bpff3Sl3uHrx"
      },
      "outputs": [],
      "source": [
        "def friend_pairs(line):\n",
        "    split = line.split()\n",
        "    user1 = int(split[0])\n",
        "    user2 = int(split[1])\n",
        "    friendship = (user1, user2)\n",
        "    return friendship\n",
        "\n",
        "# Transform the data RDD to friendship_data\n",
        "friendship_data = data.map(friend_pairs)\n",
        "\n",
        "# Group friends by user using groupByKey\n",
        "friendship_grouped = friendship_data.groupByKey()\n",
        "\n",
        "# Convert the grouped data to the desired format\n",
        "friendship_pairs = friendship_grouped.map(lambda x: (x[0], list(x[1]))).sortByKey()\n",
        "\n",
        "# Extract all distinct users from the RDD\n",
        "distinct_users = friendship_data.flatMap(lambda pair: (pair[0], pair[1])).distinct()\n",
        "\n",
        "# Calculate the number of distinct users\n",
        "number_of_users = distinct_users.count()\n",
        "\n",
        "# Create a dictionary to store the direct friends\n",
        "direct_friends_dict = {}\n",
        "\n",
        "# Convert the RDD to a list of tuples for easier processing\n",
        "friendship_list = friendship_pairs.collect()\n",
        "\n",
        "# Iterate through the list of tuples to find direct friends\n",
        "for _user in range(1, number_of_users + 1):\n",
        "    direct_friends = []\n",
        "    for user, friends in friendship_list:\n",
        "        if _user in friends:\n",
        "            direct_friends.append(user)\n",
        "    direct_friends_dict[_user] = direct_friends\n",
        "\n",
        "# Create an RDD from the direct_friends_dict\n",
        "direct_friends_rdd = sc.parallelize(direct_friends_dict.items()).sortByKey()\n",
        "\n",
        "# Combine RDD\n",
        "combined_direct_friends_rdd = direct_friends_rdd.union(friendship_pairs).reduceByKey(lambda x,y : x+y).sortByKey()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "swsibjmqlnW3"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "\n",
        "def generate_user_connections(user_friends):\n",
        "    user_id = user_friends[0]\n",
        "    friends = user_friends[1]\n",
        "    connections = []\n",
        "\n",
        "    # Create connections between the user and their friends\n",
        "    for friend in friends:\n",
        "        connection_key = (user_id, friend) if user_id < friend else (friend, user_id)\n",
        "        connections.append((connection_key, 0))\n",
        "\n",
        "    # Create connections between pairs of friends\n",
        "    friend_pairs = combinations(friends, 2)\n",
        "    for friend_pair in friend_pairs:\n",
        "        friend_1, friend_2 = friend_pair\n",
        "        connection_key = (friend_1, friend_2) if friend_1 < friend_2 else (friend_2, friend_1)\n",
        "        connections.append((connection_key, 1))\n",
        "\n",
        "    return connections\n",
        "\n",
        "friend_connections = combined_direct_friends_rdd.flatMap(generate_user_connections)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the friend_connections RDD by key\n",
        "grouped_connections = friend_connections.groupByKey()\n",
        "\n",
        "# Convert the values from ResultIterable to Python lists\n",
        "grouped_connections_with_lists = grouped_connections.mapValues(list)\n",
        "\n",
        "# Filter out pairs with 0 values\n",
        "filtered_connections = grouped_connections_with_lists.filter(lambda pair: 0 not in pair[1])\n",
        "\n",
        "# Calculate the sum of values for each key using reduceByKey\n",
        "total_connections = filtered_connections.map(lambda values: (values[0], sum(values[1])))"
      ],
      "metadata": {
        "id": "TcawO5VVdWFj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_connection_data(pair_count):\n",
        "    pair, count = pair_count\n",
        "    first_user, second_user = pair\n",
        "    connection_a = (first_user, (second_user, count))\n",
        "    connection_b = (second_user, (first_user, count))\n",
        "    return [connection_a, connection_b]\n",
        "\n",
        "user_relationships_data = total_connections.flatMap(transform_connection_data)"
      ],
      "metadata": {
        "id": "UI9VIuloiFE9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply groupByKey on the 'recommendations' RDD\n",
        "grouped_recommendations = user_relationships_data.groupByKey()\n",
        "\n",
        "# Convert the values from ResultIterable to Python lists\n",
        "grouped_recommedations_with_lists = grouped_recommendations.mapValues(list)\n",
        "\n",
        "# Sort the grouped recommendations by user ID in ascending order\n",
        "sorted_grouped_recommendations = grouped_recommedations_with_lists.sortByKey()\n",
        "\n",
        "# Sort the recommendations based on the given criteria\n",
        "def custom_sort(record):\n",
        "    user_id, recommendations = record\n",
        "    sorted_recs = sorted(recommendations, key=lambda x: (-x[1], x[0]))\n",
        "    # Check if there are fewer than 10 recommendations, and if so, keep them all\n",
        "    if len(sorted_recs) < 10:\n",
        "        return (user_id, [rec[0] for rec in sorted_recs])\n",
        "\n",
        "    # If there are more than 10 recommendations, return the top 10\n",
        "    return (user_id, [rec[0] for rec in sorted_recs[:10]])\n",
        "\n",
        "sorted_recommendations = sorted_grouped_recommendations.map(custom_sort)"
      ],
      "metadata": {
        "id": "LUJGPRYHip-F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Filter the results for the desired user ID\n",
        "# filtered_result = sorted_recommendations.filter(lambda x: x[0] in [1571])\n",
        "\n",
        "# # Collect and print the filtered results\n",
        "# filtered_data = filtered_result.collect()\n",
        "# print(filtered_data)"
      ],
      "metadata": {
        "id": "K8zEbmld0AmC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TjiPm1SqzUtn"
      },
      "outputs": [],
      "source": [
        "# Convert the results to the desired output format\n",
        "output_data = sorted_recommendations.map(lambda x: f\"{x[0]}\\t{','.join(map(str, x[1]))}\")\n",
        "\n",
        "# Save the output to a text file\n",
        "output_data.coalesce(1, True).saveAsTextFile(\"/content/test2.txt\")\n",
        "\n",
        "# Stop the Spark context\n",
        "sc.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}